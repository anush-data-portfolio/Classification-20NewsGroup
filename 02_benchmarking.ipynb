{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is a quick attempt to get a bench mark without any feature engineering, hyperparameter tuning and using a basic set of models.\n",
    "\n",
    "## Models Considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the 20 Newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Multinomial Naive Bayes...\n",
      "\n",
      "Results for Multinomial Naive Bayes:\n",
      "Accuracy: 0.6787\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.63      0.43      0.51       198\n",
      "           comp.graphics       0.58      0.64      0.61       245\n",
      " comp.os.ms-windows.misc       0.62      0.65      0.64       242\n",
      "comp.sys.ibm.pc.hardware       0.56      0.68      0.62       238\n",
      "   comp.sys.mac.hardware       0.74      0.60      0.67       250\n",
      "          comp.windows.x       0.78      0.78      0.78       260\n",
      "            misc.forsale       0.73      0.67      0.70       241\n",
      "               rec.autos       0.71      0.70      0.71       244\n",
      "         rec.motorcycles       0.43      0.75      0.55       219\n",
      "      rec.sport.baseball       0.85      0.78      0.81       261\n",
      "        rec.sport.hockey       0.88      0.89      0.88       245\n",
      "               sci.crypt       0.78      0.74      0.76       251\n",
      "         sci.electronics       0.69      0.58      0.63       249\n",
      "                 sci.med       0.82      0.80      0.81       249\n",
      "               sci.space       0.79      0.73      0.76       240\n",
      "  soc.religion.christian       0.49      0.87      0.63       245\n",
      "      talk.politics.guns       0.63      0.74      0.68       230\n",
      "   talk.politics.mideast       0.80      0.74      0.77       234\n",
      "      talk.politics.misc       0.76      0.45      0.57       207\n",
      "      talk.religion.misc       0.82      0.05      0.10       164\n",
      "\n",
      "                accuracy                           0.68      4712\n",
      "               macro avg       0.70      0.66      0.66      4712\n",
      "            weighted avg       0.71      0.68      0.67      4712\n",
      "\n",
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/Newsgroup-h-5eaQBu/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.6872\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.57      0.57      0.57       198\n",
      "           comp.graphics       0.62      0.64      0.63       245\n",
      " comp.os.ms-windows.misc       0.68      0.65      0.67       242\n",
      "comp.sys.ibm.pc.hardware       0.62      0.61      0.62       238\n",
      "   comp.sys.mac.hardware       0.75      0.65      0.70       250\n",
      "          comp.windows.x       0.80      0.75      0.77       260\n",
      "            misc.forsale       0.73      0.67      0.70       241\n",
      "               rec.autos       0.72      0.68      0.70       244\n",
      "         rec.motorcycles       0.43      0.76      0.55       219\n",
      "      rec.sport.baseball       0.80      0.80      0.80       261\n",
      "        rec.sport.hockey       0.94      0.86      0.90       245\n",
      "               sci.crypt       0.87      0.73      0.79       251\n",
      "         sci.electronics       0.57      0.65      0.60       249\n",
      "                 sci.med       0.78      0.83      0.80       249\n",
      "               sci.space       0.73      0.73      0.73       240\n",
      "  soc.religion.christian       0.67      0.74      0.70       245\n",
      "      talk.politics.guns       0.65      0.68      0.66       230\n",
      "   talk.politics.mideast       0.82      0.72      0.76       234\n",
      "      talk.politics.misc       0.60      0.60      0.60       207\n",
      "      talk.religion.misc       0.44      0.21      0.28       164\n",
      "\n",
      "                accuracy                           0.69      4712\n",
      "               macro avg       0.69      0.68      0.68      4712\n",
      "            weighted avg       0.70      0.69      0.69      4712\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Results for Random Forest:\n",
      "Accuracy: 0.6212\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.53      0.37      0.43       198\n",
      "           comp.graphics       0.54      0.54      0.54       245\n",
      " comp.os.ms-windows.misc       0.61      0.65      0.63       242\n",
      "comp.sys.ibm.pc.hardware       0.52      0.61      0.56       238\n",
      "   comp.sys.mac.hardware       0.73      0.60      0.66       250\n",
      "          comp.windows.x       0.76      0.72      0.74       260\n",
      "            misc.forsale       0.67      0.61      0.64       241\n",
      "               rec.autos       0.43      0.72      0.53       244\n",
      "         rec.motorcycles       0.60      0.64      0.62       219\n",
      "      rec.sport.baseball       0.70      0.67      0.69       261\n",
      "        rec.sport.hockey       0.76      0.82      0.79       245\n",
      "               sci.crypt       0.76      0.68      0.72       251\n",
      "         sci.electronics       0.50      0.48      0.49       249\n",
      "                 sci.med       0.71      0.74      0.72       249\n",
      "               sci.space       0.73      0.69      0.71       240\n",
      "  soc.religion.christian       0.56      0.77      0.65       245\n",
      "      talk.politics.guns       0.59      0.62      0.60       230\n",
      "   talk.politics.mideast       0.76      0.72      0.74       234\n",
      "      talk.politics.misc       0.53      0.41      0.46       207\n",
      "      talk.religion.misc       0.37      0.10      0.16       164\n",
      "\n",
      "                accuracy                           0.62      4712\n",
      "               macro avg       0.62      0.61      0.60      4712\n",
      "            weighted avg       0.62      0.62      0.62      4712\n",
      "\n",
      "\n",
      "Training Support Vector Machine...\n",
      "\n",
      "Results for Support Vector Machine:\n",
      "Accuracy: 0.6657\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.52      0.58      0.55       198\n",
      "           comp.graphics       0.55      0.62      0.58       245\n",
      " comp.os.ms-windows.misc       0.63      0.60      0.61       242\n",
      "comp.sys.ibm.pc.hardware       0.61      0.62      0.62       238\n",
      "   comp.sys.mac.hardware       0.72      0.62      0.66       250\n",
      "          comp.windows.x       0.82      0.72      0.77       260\n",
      "            misc.forsale       0.73      0.67      0.70       241\n",
      "               rec.autos       0.42      0.74      0.53       244\n",
      "         rec.motorcycles       0.62      0.67      0.64       219\n",
      "      rec.sport.baseball       0.81      0.75      0.78       261\n",
      "        rec.sport.hockey       0.96      0.81      0.88       245\n",
      "               sci.crypt       0.84      0.71      0.77       251\n",
      "         sci.electronics       0.55      0.63      0.59       249\n",
      "                 sci.med       0.77      0.80      0.79       249\n",
      "               sci.space       0.68      0.70      0.69       240\n",
      "  soc.religion.christian       0.70      0.72      0.71       245\n",
      "      talk.politics.guns       0.67      0.69      0.68       230\n",
      "   talk.politics.mideast       0.86      0.70      0.77       234\n",
      "      talk.politics.misc       0.59      0.53      0.56       207\n",
      "      talk.religion.misc       0.45      0.27      0.34       164\n",
      "\n",
      "                accuracy                           0.67      4712\n",
      "               macro avg       0.68      0.66      0.66      4712\n",
      "            weighted avg       0.68      0.67      0.67      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define and train classifiers\n",
    "classifiers = {\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Support Vector Machine': SVC(kernel='linear', C=1)\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    # Evaluate and print results\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=newsgroups.target_names)\n",
    "    \n",
    "    print(f\"\\nResults for {name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "    # save the results and report\n",
    "    # create a folder called results\n",
    "    import os \n",
    "    if not os.path.exists(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    "        \n",
    "    with open(f\"results/{name}.txt\", \"w\") as f:\n",
    "        f.write(f\"Results for {name}:\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "        f.write(f\"Classification Report:\\n{report}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These accuracy scores acts as a good bench mark, looking at the report of these models will tell us a lot more about the data and the spread\n",
    "- When I was going over the report , some thing striked, the articles can have different words lenghts and articles with big size ( with a lot of words) can have an imapct on the classification we have to normalise it so that a single category doesnt have too much importance. \n",
    "- the article size imbalance is something we need to keep in mind when we preprocess the text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Newsgroup-h-5eaQBu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
